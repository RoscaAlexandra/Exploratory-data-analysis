---
title: 'Exploratory Data Analysis (EDA): Categorical Data & Quality Control'
output:
  html_document:
    df_print: paged
---
&nbsp;

&nbsp;


  EDA is not a formal process with a strict set of rules. More than anything, EDA is a state of mind. During the initial phases of EDA you should feel free to investigate every idea that occurs to you. Some of these ideas will pan out, and some will be dead ends. As your exploration continues, you will home in on a few particularly productive areas that you’ll eventually write up and communicate to others.

  EDA is an important part of any data analysis, even if the questions are handed to you on a platter, because you always need to investigate the quality of your data. Data cleaning is just one application of EDA: you ask questions about whether your data meets your expectations or not. To do data cleaning, you’ll need to deploy all the tools of EDA:visualisation, transformation, and modelling.

  EDA is an iterative cycle. You:
    - Generate questions about your data.
    - Search for answers by visualising, transforming, and modelling your data.
    - Use what you learn to refine your questions and/or generate new questions.
&nbsp;



### 1. Categorical Data

####        	&#32;  	&#32;  a) Univariate analysis

####        	&#32;  	&#32;  b) Multivariate analysis


### 2. Missing values



### 3. Outliers

***

## 1. Categorical Data


#### a) Univariate analysis
***

  _Univariate analysis_ is the simplest form of analyzing data. “Uni” means “one”, so in other words your data has only one variable. It doesn’t deal with causes or relationships and it’s major purpose is to describe; It takes data, summarizes that data and finds patterns in the data.
  You have several options for describing data with univariate data. E.g.:
    - Frequency Distribution Tables
    - Bar Charts
    - Pie Charts
    
```{r, echo=FALSE, message=FALSE}
library("gridExtra")
library("ggplot2")
library("vcd")
library("vcdExtra")
library(visdat)
library("purrr")
library(dplyr)
require(lattice)
```

  In the scope of presenting this basic type of data and how it can be represented, we chose the data set called "Virginia Death Rates in 1940" that represents the mortality rate based on sex, age and region (rural or urban area). 
  We separated each category and analised the graphic results. 
  
```{r, message=FALSE}
VADeathRate <- as.data.frame.table(VADeaths)
knitr::kable(VADeathRate, format="markdown")
```
&nbsp;

  First, we used basic bar charts to analise the data.

```{r, message=FALSE}
#Grouping data based on age

ageGrouping <- aggregate(VADeathRate$Freq, by=list(Age=VADeathRate$Var1), FUN=mean)

#Grouping data based on category

catGrouping <- aggregate(VADeathRate$Freq, by=list(Category=VADeathRate$Var2), FUN=mean)

#Grouping data based on region

type1Grouping <- aggregate(VADeathRate$Freq, by=list(gender=VADeathRate$Var2), FUN=mean)
type1Grouping$Place <- c("Rural", "Rural", "Urban", "Urban")
placeGrouping <- aggregate(type1Grouping$x, by=list(Place=type1Grouping$Place), FUN=mean)

```
  
```{r, message=FALSE}
#Plotting different results

p1 <- ggplot(placeGrouping, aes(Place, x, fill=Place, width=x*0.01)) +
  
  geom_bar(stat="identity") +
  ylab("Death rate")

p2 <- ggplot(ageGrouping, aes(Age, x, fill = Age)) +
  
  geom_bar(stat="identity") +
  ylab("Death rate")



p3 <- ggplot(catGrouping, aes(Category, x, fill=Category, width=x*0.02)) +
  geom_bar(stat="identity") +
  geom_col(position = "dodge") +
  ylab("Death rate")

grid.arrange(p1, p2, p3, top = "Bar chart representation of Virginia Death Rates")

```

&nbsp;

&nbsp;



We also used pie charts to represent the data. As it was expected, the death rate increased with the age, it's also larger for people in the urban area, but surprisingly, we also concluded that the death rate is larger for males than for females.

```{r}
par(mfrow=c(1,3),oma = c(0, 0, 1.5, 0))
with(placeGrouping, pie(x, labels=Place, clockwise=TRUE,
                      col=rainbow(2), radius=1))
with(ageGrouping, pie(x, labels=Age, clockwise=TRUE,
               col=rainbow(5), radius=1))
with(catGrouping, pie(x, labels=Category, clockwise=TRUE,
                      col=rainbow(4), radius=1))
mtext("Pie representation of Virginia Death Rates", outer = TRUE, cex = 1.01)
```

  
  
***
#### b) Multivariate analysis

  Multivariate analysis (MVA) is based on the principles of multivariate statistics, which involves observation and analysis of more than one statistical outcome variable at a time. Typically, MVA is used to address the situations where multiple measurements are made on each experimental unit and the relations among these measurements and their structures are important.

##### Doubledeckers
  For our first analisys, we chose a dataset that represents a University of California admission study. 
  
  
```{r}
uniAdmission <- as.data.frame.table(UCBAdmissions)

#Admission depending on gender
doubledecker(Admit ~ Gender, data = UCBAdmissions, margins = c(2,7, 2, 2), keep_aspect_ratio = TRUE, gp = gpar(fill = c("#0caa00","#c70b00")))
#Admission depending on dept
doubledecker(Admit ~ Dept, data = UCBAdmissions, margins = c(2,6, 2, 1), keep_aspect_ratio = TRUE, gp = gpar(fill = c("#0caa00","#c70b00")))
#Admission depending on dept and gender
doubledecker(Admit ~ Dept + Gender, data = UCBAdmissions, margins = c(0,6, 3, 0), keep_aspect_ratio = TRUE, gp = gpar(fill = c("#0caa00","#c70b00")))
```

##### Mosaics

  Mosaic plots represent another possible graphic representation of multivariate variables. 
  Since the "Virginia Deathrates" actually represents a multivariate dataset (age, sex and area are interdependent), we studied it even deeper exploiting the categories and using mosaics.

```{r}
#Death rates mosaics
addedCols <- VADeathRate
addedCols$Place <- c("Rural", "Rural", "Rural", "Rural", "Rural", "Rural", "Rural", "Rural", "Rural", "Rural", "Urban", "Urban", "Urban", "Urban", "Urban", "Urban", "Urban", "Urban", "Urban", "Urban")
addedCols$Sex <- c("Male", "Male", "Male", "Male", "Male", "Female", "Female", "Female", "Female", "Female", "Male", "Male", "Male", "Male", "Male", "Female", "Female", "Female", "Female", "Female")
par(mfrow=c(1,3))
m1 <- mosaicplot(xtabs(Freq ~ Sex, data=addedCols), main="", color = "#0c9cac", border = "black")
m2 <- mosaicplot(xtabs(Freq ~ Sex + Var1, data=addedCols),main="", color = "#0c9cac", border = "black")
m3 <- mosaicplot(xtabs(Freq ~ Sex + Var1 + Place, data=addedCols),main="", color = "#0c9cac", border = "black")

```

&nbsp;

##### Fluctuation diagrams

  Fluctuation diagrams are good for representing large contingency tables or transition matrices, where there is no reason to differentiate between the row variable and the column variable. 
  If there is a large number of combinations and only a few occur at all, then a fluctuation diagram is valuable for revealing this information and for identifying categorical clusters. The following figure shows a fluctuation diagram for eight binary variables of the Zoo dataset in the package seriation. Several distinct groupings stand out and there are many feature combinations for which there are no animals in the dataset.

```{r, echo=FALSE, message=FALSE}
fluctile <- function(tab, dir = "b", just = "c", hsplit = FALSE,shape ="r", gap.prop = 0.1,border = NULL, label = TRUE, lab.opt = list(), add = FALSE, maxv = NULL, tile.col = hsv(0.1,0.1,0.1,alpha=0.6), bg.col = ifelse(add,NA,"lightgrey"), tile.border = NA, vp = NULL,  ...  ){
  #tab <- t(tab)
  dm <- dim(tab)
  if(is.null(maxv)){
    maxv <- max(tab)
  }
  
  nd <- length(dm)
  
  # expand gap.prop
  tmp <- rep(tail(gap.prop,1),nd)
  tmp[seq_along(gap.prop)] <- gap.prop
  gap.prop <- tmp
  
  #if(add){
  #	bg.col = NA
  #}
  if( dir %in% c("vh","hv","b","both")){
    dir <- "b"
  }
  if( dir %in% c("h","horizontal")){
    dir <- "h"
  }
  if( dir %in% c("v","vertical")){
    dir <- "v"
  }
  if(nchar(just)[1] == 2){
    just <- c(substr(just[1],1,1),substr(just[1],2,2))
  }
  just <- sapply(just, function(j){
    switch(j, t="top", b = "bottom", c = "center", r = "right", l = "left", NULL)
  })
  if("abbrev" %in% names(lab.opt)){
    abbrev <- rep(lab.opt$abbrev,nd)[1:nd]
  }else{
    abbrev <- rep(40,nd)
  }
  if("lab.cex" %in% names(lab.opt)){
    lab.cex <- lab.opt$lab.cex
  }else{
    lab.cex <- 1.2
  }
  if("rot" %in% names(lab.opt)){
    rot <- lab.opt$rot
  }else{
    rot <- 65
  }
  if("lwd" %in% names(lab.opt)){
    tile.lwd <- lab.opt$lwd
  }else{
    tile.lwd <- 1
  }
  data <- as.data.frame(as.table(tab))
  
  
  
  # logical vector for the split directions
  if(length(hsplit) == 1){
    hsp <- rep( c(hsplit,!hsplit),ncol(data) )[1:nd] 
    hsplit <- hsp
  }else{
    hsp <- hsplit
  }
  for(i in which(!hsp) ){
    data[,i] <- factor(data[,i], levels = rev(levels(data[,i])))	
  }
  tab <- xtabs(Freq~., data = data)
  
  # prepare for border and labs
  
  
  label <- rep(label,nd)[1:nd]
  rot <- rep(rot,2)[1:2]
  lab.cex <- rep(lab.cex,2)[1:2]
  
  
  abbrev <- abbrev * as.integer(label)
  
  
  
  nx <- max(sum(hsp*label),1) # min 2
  ny <- max(sum( (!hsp)*label),1)
  
  
  if(is.null(border)){
    border <- 0.1
  }
  if(length(border) == 1){
    border <- 	border * c( nx/(nx+1),1/(nx+1),1/(ny+1), ny/(ny+1) )
  }
  if(length(border) == 2){
    border <- 	c( border[1] * c( nx/(nx+1),1/(nx+1)) , border[2] * c( ny/(ny+1),1/(ny+1)) )
  }
  
  
  
  wph <- dm[2]/dm[1]
  #dev.new( width = 1000*(1-gap.prop)*wph + gap.prop*1000, height = 1000 )
  
  
  if(is.null(vp)){
    if(!add){
      grid.newpage()
    }
    vp <- viewport()
  }
  
  
  #if(!is.null(vp)){
  if(!inherits(vp,"viewport")){
    #stopifnot(length(vp)>1)
    if(length(vp) < 2){
      stop("Wrong viewport specification.")
    }
    if(is.null(current.viewport()$layout)){
      print("No layout specified. Try:")
      print("mat.layout <- grid.layout(nrow, ncol); grid.newpage(); vp.mat <- viewport(layout = mat.layout); pushViewport(vp.mat)")
    }
    
    vp <- viewport(layout.pos.row = vp[1], layout.pos.col = vp[2])
    
  }
  pushViewport(vp)
  #}else{
  
  #}
  
  vp0 = viewport(x = border[1] + (1-border[1]-border[2])/2 , y = border[3] + (1-border[3]-border[4])/2, width = 1-border[1]-border[2], height = 1-border[3]-border[4],name="base")
  if(length(dm)==2){
    
    #color workaround:
    #if(shape %in% c("r","c")){
    nn <- length(tab)
    tile.col <- rep(tile.col, ceiling(nn/length(tile.col)))[1:nn]
    tile.border <- rep(tile.border, ceiling(nn/length(tile.border)))[1:nn]
    dim(tile.col) <- dim(tile.border) <- dim(tab)
    
    tile.col = tile.col[nrow(tile.col):1,]
    tile.border = tile.border[nrow(tile.border):1,]
    #}
    
    
    pushViewport(vp0)
    if(!add){
      #grid.newpage()
      grid.rect(gp = gpar(fill=rgb(0,0,0,alpha=0.05),col=NA))
    }
    # handle the last 2 dimensions
    if( hsp[1] ){
      if( hsp[2] ){
        dim(tab) <- c(1, prod(dim(tab)))	
      }else{
        tab <- as.table(t(tab))	
        dm <- dim(tab)
      }
    }else{
      if( !hsp[2] ){
        dim(tab) <- c( prod(dim(tab)), 1)	
      }
    }
    gridfluc(tab,dir,just,shape,gap.prop, maxv=maxv, bg = bg.col, col = tile.col,border = tile.border, lwd = tile.lwd)
    popViewport()
    
    # add labels
    if(any(label)){
      
      rn <- abbreviate(dimnames(tab)[[1]],abbrev[1])
      cn <- abbreviate(dimnames(tab)[[2]],abbrev[2])
      
      m <- dm[2]
      xc <- seq(0.5,m-0.5) / m
      xc <- xc - gap.prop[2]/(m-1)/2
      xc <- xc/(1 - gap.prop[2]/(m-1))
      
      
      n <- dm[1]
      yc <- seq(0.5,n-0.5) / n
      yc <- yc - gap.prop[1]/(n-1)/2
      yc <- yc/(1 - gap.prop[1]/(n-1))
      
      
      vpR <- viewport(x = border[1]/2, y = border[3] + (1-border[3] -border[4])/2, width = border[1], height = 1-border[3]-border[4],name="rowlabs")
      pushViewport(vpR)
      y0<-0.5
      yjust <- "centre"
      x0<-0.5
      xjust <- "centre"
      
      if(rot[1] == 90){
        x0 <- 0.7
      }
      if(rot[1] == 0){
        x0 <- 0.9
        xjust <- "right"
      }
      if(rot[2] == 0){
        y0 <- 0.1
        yjust <- "left"
      }
      if(rot[2] == 90){
        y0 <- 0.3
      }
      
      
      
      grid.text(rn, x = x0, y = yc, gp = gpar(cex=lab.cex[1]), rot = rot[1], just <- xjust)
      popViewport()
      
      vpC <- viewport(x = border[1] + (1-border[1]-border[2])/2, y = 1-border[4]/2, width = 1-border[1]-border[2], height = border[4],name="collabs")
      pushViewport(vpC)
      grid.text(cn, x = xc, y = y0,rot = 90-rot[2], gp = gpar(cex=lab.cex[2]),just = yjust)
      
      popViewport()
    }
    
    #if(!add | !is.null(vp)){
    #	try( upViewport(), silent = TRUE )
    #}
    
    #if(!is.null(vp)){
    #	try( upViewport(), silent = TRUE )
    #}
    upViewport()
    
    return(vp0)
  }else{
    e1 <- new.env()
    ltrs <- expand.grid(letters,letters,letters)
    
    e1$vpn <- paste(ltrs[,1],ltrs[,2],ltrs[,3],sep="")
    e1$k <- 0
    hsplit <- !hsplit
    ss <- fluctree(dm,parent=vp0, hsplit=hsp, gap.prop=gap.prop, env=e1)
    #grid.newpage()
    pushViewport(ss)
    seekViewport("base")
    
    e1$k <- 0	
    
    #flucplot creates a viewport tree in the e1 environment
    flucplot(tab = tab, gap.prop = gap.prop, hsplit = hsp, env=e1)
    
    # use the tree in e1 to plot the 2-dimensional fluctuation diagrams
    mapply(function(x,y,hs,gp) {
      #pushViewport(ss)
      seekViewport(y)
      
      if(hsp[length(hsp)-1] & hsp[length(hsp)]) dim(x) <- c(1, prod(dim(x)))
      if(!hsp[length(hsp)-1] & !hsp[length(hsp)]) dim(x) <- c( prod(dim(x)), 1)
      if(hsp[length(hsp)-1] & !hsp[length(hsp)]) x <- as.table(t(x))
      
      #TODO: do something similar for the labels
      
      gridfluc(x,dir,just,shape,gp, maxv=maxv, bg = bg.col, col = tile.col, border = tile.border, lwd = tile.lwd)
    }, x = e1$tablist, y = e1$namlist, hs = e1$hslist, gp = e1$gplist)	
    
    upViewport()
    # go back to surface
    for(i in 1:(nd-2)){
      upViewport()
    }
    
    #######################################################################################################	
    # -------------------------------------------- LABELING  -------------------------------------------- #
    #
    #labs <- lapply(data[,-(nd+1)],function(s) abbreviate(levels(as.factor(s)),abbrev))
    labs <- mapply( function(y,z) abbreviate(levels(y),z)  ,y = data[,-(nd+1)], z = as.list(abbrev), SIMPLIFY = FALSE)
    
    ind <- label & (!hsp)
    if(any(ind)){
      
      
      vp1 <- viewport(x = border[1]/2, y = border[3] + (1-border[3]-border[4])/2, width = border[1], height = 1-border[3]-border[4],name="ylab")
      pushViewport(vp1)
      #grid.rect(0.5,0.5,1,1,gp=gpar(fill=rgb(0,0,0,alpha=0.1)))
      
      
      # create labels for the y-axis
      
      
      ind <- which(ind)
      rpt <- c(1,cumprod( dim(tab)[ind] ))
      
      nlvl <- dim(tab)[ind]
      gaps <- 0
      blocksize <- 1
      
      row.gap.prop <- gap.prop[!hsp]
      
      for( i in 1:ny ){
        # viewport for the label column
        currvp <- viewport( x = 1/ny/2+ (i-1)/ny, y = 0.5, width = 1/ny, height = 1)
        pushViewport(currvp)
        
        rlabs <- rep(labs[[ ind[i] ]], rpt[i])
        
        nl <- length(rlabs)
        
        
        # the gaps for the new dimension
        newgaps <- c(0:(nlvl[i]-1)) * blocksize * row.gap.prop[i] / (nlvl[i]-1)
        newgaps <- rep(newgaps, rpt[i])
        
        gaps <- rep(gaps, each = nlvl[i])
        
        x <- 0.5
        if( i == 1 ){
          y <- seq(1/nl/2,1-1/nl/2,1/nl)*prod(1-row.gap.prop[1:i]) + newgaps  #seq*((1-gap.prop)^i)
        }else{
          # the old coordinates +- the new gaps and cellwidths
          y <- rep(y,each = nlvl[i]) + newgaps - max(newgaps)/2 + (1-row.gap.prop[i])*blocksize * rep(seq(1/nlvl[i]/2,1-1/nlvl[i]/2,1/nlvl[i])-0.5, rpt[i])
        }
        
        grid.text(rlabs, x = x, y = y , rot = rot[1], gp = gpar(cex=lab.cex[1]))
        #grid.points( x = rep(x,length(y)), y = y , gp = gpar(col="red"))
        popViewport()
        
        blocksize <- blocksize * (1-row.gap.prop[i]) / nlvl[i]
      }
      popViewport()
      
      
      #grid.rect(0.5,0.5,1,1,gp=gpar(fill=rgb(0,0,0,alpha=0.1)))
    } # any ind
    
    ind <- label & hsp
    if(any(ind)){
      
      vp2 <- viewport(x = border[1] + (1-border[1]-border[2])/2, y = 1 - border[4]/2, width = 1-border[1]-border[2], height = border[4],name="xlab")
      pushViewport(vp2)
      
      ind <- which(ind)
      
      
      rpt <- c(1,cumprod( dim(tab)[ind] ))
      
      nlvl <- dim(tab)[ind]
      gaps <- 0
      blocksize <- 1
      col.gap.prop <- gap.prop[hsp]
      
      for( i in 1:nx ){
        # viewport for the label column
        
        currvp <- viewport( x = 0.5, y = 1 - 1/nx/2 - (i-1)/nx, width = 1, height = 1/nx)
        pushViewport(currvp)
        
        #labs <- rep(levels(data[, ind[i]]), rpt[i])
        clabs <- rep(labs[[ ind[i] ]], rpt[i])
        nl <- length(clabs)
        
        
        newgaps <- c(0:(nlvl[i]-1)) * blocksize * col.gap.prop[i] / (nlvl[i]-1)
        newgaps <- rep(newgaps, rpt[i]) 
        
        #cat("labeling variable", names(data)[ind[i]], " with nlvl = ", nlvl[i], " and levels = ", labs," and rpt = ", rpt[i]) 
        
        y <- 0.5
        if( i == 1 ){
          x <- seq(1/nl/2,1-1/nl/2,1/nl)*prod(1-col.gap.prop[1:i]) + newgaps # seq*((1-gap.prop)^i)
        }else{
          x <- rep(x,each = nlvl[i]) + newgaps - max(newgaps)/2 + (1-col.gap.prop[i])*blocksize * rep(seq(1/nlvl[i]/2,1-1/nlvl[i]/2,1/nlvl[i])-0.5, rpt[i])
        }
        #cat( "lab.x = ",x)
        grid.text(clabs, x = x, y = y , rot = 90-rot[2], gp = gpar(cex=lab.cex[2]))
        #grid.points( x = x, y = rep(y,length(x)) , gp = gpar(col="red"))
        popViewport()
        
        blocksize <- blocksize * (1-col.gap.prop[i]) / nlvl[i]
      }
      popViewport()
    }# any ind
    #
    # -------------------------------------------- LABELING  -------------------------------------------- #
    #######################################################################################################	
    #try(popViewport(),silent = TRUE)
    
    #if(!add){
    #	try( upViewport(), silent = TRUE )
    #}
    
    #if(!is.null(vp)){
    #	try( upViewport(), silent = TRUE )
    #}
    upViewport()
    
    return(invisible(ss))
  }
}	

flucplot <- function(tab, gap.prop, hsplit, env, ...){
  if(! "tablist" %in% ls(env) ){
    env$tablist = list()
    env$namlist = list()
    env$hslist = list()
    env$gplist = list()
    env$k2 = 0
  }
  
  dm <- dim(tab)
  
  
  
  #print(env$k)
  #print(env$vpn[env$k])
  
  if(length(dm) == 2){
    
    
    env$k2 <- env$k2+1
    k2 <- env$k2
    env$tablist[[k2]] <- tab
    env$namlist[[k2]] <- env$vpn[env$k]
    env$hslist[[k2]] <- hsplit
    env$gplist[[k2]] <- gap.prop
    env$k <- env$k+1
  }else{
    hsplit <- hsplit[-1]		
    gap.prop <- gap.prop[-1]
    env$k <- env$k+1
    apply(tab,1,function(z){
      flucplot(z,gap.prop, hsplit, env)
    })
  }
  #
  
  return(invisible(TRUE))
}

fluctree <- function(dims,parent, hsplit, gap.prop, env, ...){
  nv <- dims[1]
  dims <- dims[-1]
  
  
  if(hsplit[1]){
    w <- rep((1-gap.prop[1])/nv,nv)
    x <-  w/2 + 0:(nv-1)*(w + gap.prop[1]/(nv-1)) 
    h <- rep(1,nv)
    y <- rep(0.5,nv)
  }else{
    h <- rep((1-gap.prop[1])/nv,nv)
    y <- h/2 + 0:(nv-1)*(h + gap.prop[1]/(nv-1))
    w <- rep(1,nv)
    x <- rep(0.5,nv)
  }
  #	if(length(hsplit) == 1){
  #		hsplit <- !hsplit	
  #}else{
  hsplit <- hsplit[-1]	#hsplit[-length(hsplit)]#	
  #}
  gap.prop <- gap.prop[-1]
  
  if(length(dims) > 2){
    children <- vpList()
    for(i in 1:nv){
      env$k <- env$k+1
      tmp <- viewport( x[i],y[i],w[i],h[i],just="centre" , name = env$vpn[env$k])
      children[[i]] <- fluctree(dims,parent = tmp,hsplit, gap.prop, env)
      
    }
    return(vpTree(parent,children))
    
  }else{
    children <- vpList()
    for(i in 1:nv){
      env$k <- env$k+1
      children[[i]] <- viewport( x[i],y[i],w[i],h[i],just="centre" , name = env$vpn[env$k])
    }
    return(invisible(vpTree(parent,children)))
  }
  
  
}

gridfluc <- function(tab,dir = "both", just = "centre", shape = "r", gap.prop = 0.1, maxv = NULL,vp = NULL, col = NULL, bg = NULL, border = NA, lwd = 1, ...){
  
  gap.prop <- rep(gap.prop,2)
  
  if(shape != "r" ){
    just <- "centre"
    dir <- "b"
  }
  #if(just[1] == "c") just[1] <- "centre"
  
  if( is.null(bg) ){
    bg <- NA
  }
  if( is.null(col) ){
    col <- hsv(0,0,0,alpha=0.7)
  }
  
  n <- nrow(tab)
  m <- ncol(tab)
  w <- (1-gap.prop[2])/m
  h <- (1-gap.prop[1])/n
  #centered x- and y-coords:
  x <-  w/2  
  y <- h/2 
  
  if(n > 1){
    y <- y + 0:(n-1)*(h+gap.prop[1]/(n-1))	
  } 
  if(m > 1){
    x <- x + 0:(m-1)*(w+gap.prop[2]/(m-1))
  }  
  if(is.null(maxv)){
    maxv <- max(tab)	
  }
  
  
  draw2( h, w,  t(replicate(n,x)) , replicate(m,y), border = NA,bg=bg, lwd = lwd, vp=vp, just = "centre")
  
  if("right" %in% just){
    x <- x+w/2
  }
  if("left" %in% just){
    x <- x-w/2
  }
  if("top" %in% just){
    y <- y+h/2
  }
  if("bottom" %in% just){
    y <- y-h/2
  }
  if(dir == "b"){
    tab <- sqrt(tab/maxv)
    ht <- as.matrix(h*tab)
    wt <- as.matrix(w*tab)
  }
  if(dir == "v"){
    tab <- tab/maxv
    wt <- as.matrix(w*tab^0)
    ht <- as.matrix(h*tab)
  }
  if(dir == "h"){
    tab <- tab/maxv
    ht <- as.matrix(h*tab^0)
    wt <- as.matrix(w*tab)
  }
  if(dir == "n"){
    tab <- tab/maxv
    ht <- matrix(0,ncol=ncol(tab), nrow=nrow(tab))
    wt <- ht
    ht[tab > 0] <- h
    wt[tab > 0] <- w
  }
  if(shape == "r"){
    draw2(ht, wt,  t(replicate(n,x)), replicate(m,y), border = border,bg=col, lwd = lwd, vp=vp, just = just)
  }
  
  if(shape == "c"){
    draw3(R = ht/2* (min(n,m)/max(m,n)), t(replicate(n,x)), replicate(m,y), border = border,bg=col, lwd = lwd, vp=vp, just = just)
  }
  if(shape %in% c("o", "d")){
    if(shape == "o"){
      angles <- seq(22.5,360,45)/180*pi
      wt <- wt / cos(pi/8)
      ht <- ht / cos(pi/8)
    }
    if(shape == "d"){
      angles <- seq(0,360,90)/180*pi
    }
    #if(shape == "c"){
    #	angles <- seq(0,360,1)/180*pi
    #}
    corners <-  cbind( cos(angles), sin(angles))
    #mapply(function(x,y,h,w,c){
    #					   grid.polygon(x = x+corners[,1]*w/2, y = y+corners[,2]*h/2, gp = gpar(col = border, fill = c, alpha = 1))
    #		   }, x = t(replicate(n,x)), y = replicate(m,y), h = ht, w = wt, c = rep(col,length(ht))[1:length(ht)] )
    ncr <- length(corners[,1])
    colv <- rep(col,length(ht))
    
    x2 <- rep(x,each=n*ncr) + rep(corners[,1], n*m )*rep(wt,each=ncr)/2
    y2 <- rep(rep(y,m),each=ncr) + rep(corners[,2], n*m )*rep(ht,each=ncr)/2
    #grid.polygon(x2, y2 , gp = gpar(col = border, fill = rep(colv, each = ncr), alpha = 1), 
    #id = rep(1:(m*n),each=ncr))
    
    uc <- unique(colv)
    colv <- rep(colv, each = ncr)
    idv <- rep(1:(m*n),each=ncr)
    for(cc in uc){
      ii <- which(colv == cc)
      grid.polygon(x2[ii], y2[ii] , gp = gpar(col = border, fill = cc, alpha = 1,lwd = lwd), 
                   id = idv[ii])
    }
    
  }
  
  return(invisible(TRUE))	
}


draw2 <- function (H, W, X, Y, alpha = 1, border = "black", bg = "white", lwd = 1, 
                   vp = NULL, just = "centre") 
{
  if(!is.null(dim(border))){
    border[which(H*W == 0)] <- NA
  }
  if(!is.null(dim(bg))){
    bg[which(H*W == 0)] <- NA
  }
  grid.rect(x = unit(X, "npc"), y = unit(Y, "npc"), width = unit(W, 
                                                                 "npc"), height = unit(H, "npc"), just = just, default.units = "npc", 
            name = NULL, gp = gpar(col = border, fill = bg, alpha = alpha, lwd = lwd), 
            draw = TRUE, vp = vp)
}



draw3 <- function (R, X, Y, alpha = 1, border = "black", bg = "white", lwd = 1,
                   vp = NULL, just = "centre") 
{
  if(!is.null(dim(border))){
    border[which(R == 0)] <- NA
  }
  if(!is.null(dim(bg))){
    bg[which(R == 0)] <- NA
  }
  grid.circle(x = unit(X, "npc"), y = unit(Y, "npc"), r = unit(R, 
                                                               "npc"), default.units = "npc", 
              name = NULL, gp = gpar(col = border, fill = bg, alpha = alpha,lwd = lwd), 
              draw = TRUE, vp = vp)
}

addrect = function( vp ,breaks, col = "red", lwd = 2, lty = 1, gap.prop = 0, rev.y = FALSE, fill = NULL){
  yc <- breaks[[1]]
  xc <- breaks[[2]]
  
  nyc <- length(yc)
  nxc <- length(xc)
  stopifnot( nxc > 1 & nxc==nyc)
  n <- yc[nyc]
  m <- xc[nxc]
  pushViewport(vp)
  
  xc <- (xc-1)/(m-1)
  xc <- xc - gap.prop/(m-1)/2
  xc <- xc/(1 - gap.prop/(m-1))
  xc[1] <- 0
  xc[nxc] <- 1
  
  yc <- (yc-1)/(n-1)
  yc <- yc - gap.prop/(n-1)/2
  yc <- yc/(1 - gap.prop/(n-1))
  yc[1] <- 0
  yc[nyc] <- 1
  
  dyc <- diff(yc)
  dxc <- diff(xc)
  if(rev.y){
    mapply( function(x,y,w,h){
      grid.rect(x,y,w,h,gp=gpar(fill=fill,col=col,lwd=lwd, lty = lty),just=c("left","top"))
    }, x = as.list( xc[-nxc] ), y = as.list( 1-yc[-nyc] ),w = as.list(dxc),h = as.list(dyc))
    
  }else{
    mapply( function(x,y,w,h){
      grid.rect(x,y,w,h,gp=gpar(fill=fill,col=col,lwd=lwd, lty = lty),just=c("left","bottom"))
    }, x = as.list( xc[-nxc] ), y = as.list( yc[-nyc] ),w = as.list(dxc),h = as.list(dyc))
  }
  
  upViewport()
  return(invisible(TRUE))
  
}


cfluctile <- function(x, tau0 = NULL, method="Kendall", nsplit = NULL, maxsplit = NULL,  trafo = I, gap.prop = 0.2, 
                      floor = 0, rev.y = FALSE, add = FALSE, shape = "r", just = "c", dir = "b", plot = TRUE ,rect.opt = list(), border = NULL, label = TRUE, lab.opt = list(), tile.col = hsv(0.1,0.1,0.1,alpha=0.6), tile.border = NA, bg.col = "lightgrey", ...){
  
  stopifnot(inherits(x,"table") | inherits(x,"matrix") )
  stopifnot( length(dim(x)) == 2 )
  
  # get parameters for rectangles
  if( "lwd" %in% names(rect.opt) ){
    lwd <- rect.opt$lwd
  }else{
    lwd <- 2
  }
  if( "lty" %in% names(rect.opt) ){
    lty <- rect.opt$lty
  }else{
    lty <- 1
  }
  
  if( "col" %in% names(rect.opt) ){
    col <- rect.opt$col
  }else{
    col <- "red"
  }
  if( "fill" %in% names(rect.opt) ){
    fill <- rect.opt$fill
  }else{
    fill <- alpha(col,0.05)
  }
  
  
  #if(kendalls(x) < 0){
  #    x <- x[,ncol(x):1]
  #    print("Reversed column category order...")
  #}
  
  if( method %in% c("Kendall","kendall","tau",1) ){
    method <- as.integer(1)	
  }
  if( method %in% c("kappa","Cohen",2) ){
    method <- as.integer(2)	
  }
  if( method %in% c("WBCI","wbci","WBCC",3) ){
    method <- as.integer(3)	
  }
  if( method %in% c("BCI","bci","BCC",4) ){
    method <- as.integer(4)	
  }
  if( method %in% c("R","r","res","resid","residual",5) ){
    method <- as.integer(5)	
  }
  if( method %in% c("minres","mr","min.res",6) ){
    method <- as.integer(6)	
  }
  ret.int <- ( storage.mode(x) == "integer" )
  storage.mode(x) <- "numeric"
  
  
  
  n <- nrow(x)
  m <- ncol(x)
  if(is.null(maxsplit)){
    maxsplit <- min(n,m)+1
  }
  if(!is.null(nsplit)){
    stopifnot(nsplit <= maxsplit)
    tau0 <- -1
    maxsplit <- nsplit
  }
  if(maxsplit == 1){
    singlesplit <- 1
  }else{
    singlesplit <- min(n,m)+1
  }
  
  #storage.mode(x) <- "integer"
  if(is.null(tau0)){
    if(method == 1){
      tau0 <- kendalls(x)
    }
    if(method == 2){
      tau0 <- cohen(x)
    }
    if(method == 3){
      tau0 <- 1 - WBCI(x)
    }
    if(method == 4){
      tau0 <- 1 - BCI(x)
    }
    if(method == 5){
      #ix <- itab(x)
      tau0 <- 0.9 #<- 1 - exp(min( (x-ix)/sqrt(ix)  ))
    }
    if(method == 6){
      #ix <- itab(x)
      tau0 <- sum( abs(x - itab(x))/sqrt(itab(x)) )/sum(x)/2
    }
  }
  
  if( floor > 0 ){
    x2 <- apply(x,1:2, function(z){
      ifelse(z < floor, 0, z)
    })
    #storage.mode(x2) <- "integer"
    cuts <- .Call("getclust",x2,as.integer(dim(x)),tau0,method,as.integer(singlesplit))
  }else{
    cuts <- .Call("getclust",x,as.integer(dim(x)),tau0,method,as.integer(singlesplit))
  }
  
  
  r <- length(cuts)/4 #/2
  if(rev.y){
    x <- as.table(x[nrow(x):1,]	)
  }
  b1 <- c(1,cuts[1:r]+1)
  b2 <- c(1,cuts[(r+1):(r+r)]+1)
  tau.values <- cuts[(2*r+1):(3*r-1)]
  cut.ids <- cuts[(3*r+1):(4*r-1)]
  
  if( r > 1 ){
    # get cut order (tau before level!)
    nc <- length(cut.ids)
    xtci <- c(0,cut.ids,0)
    lp <- rp <- NULL #left and right parent cut
    for(i in 2:(nc+1) ){
      lp[i-1]	<- max( which( xtci[1:(i-1)] < xtci[i]))
      rp[i-1]	<- i + min( which( xtci[(i+1):(nc+2)] < xtci[i]))
    }
    parents <- cbind(lp,rp)
    # level of left and right parent
    rlp <- c(0,cut.ids,0)[lp]
    rrp <- c(0,cut.ids,0)[rp]
    lrrp <- cbind(rlp,rrp)
    # parent level
    parent <- apply(lrrp,1,which.max)
    for(i in seq_along(parent)){
      parent[i] <- parents[i,parent[i]]
    }
    #parent.tau <- c(1,tau.values)[parent]
    
    
    cut.rank <- rep(0,nc)
    cut.rank[which(cut.ids==1)] <- (k<-1)
    acc.parents <- c(TRUE,rep(FALSE,nc))
    acc.parents[which(cut.ids==1)+1] <- TRUE
    while(!all(acc.parents)){
      # candidates: parent accepted and not an acc. parent already
      (candidates <- which( acc.parents[parent] & !acc.parents[-1]))
      (best <- candidates[ which.max( tau.values[candidates])])
      acc.parents[best+1] <- TRUE
      cut.rank[best] <- (k<-k+1)
      
    }
  }else{
    # r == 1
    cut.rank <- 1
  }
  #cut.rank <- rank(tau.values+cut.ids) # old: this used level before tau
  exclude <- cut.rank > maxsplit
  
  if( any( exclude) ){
    exclude <- which(exclude)
    b1 <- b1[-(exclude+1)]
    b2 <- b2[-(exclude+1)]
    cut.rank <- cut.rank[-exclude]
    tau.values <- tau.values[-exclude]
    cut.ids <- cut.ids[-exclude]
  }
  breaks <- list(b1,b2)
  r <- length(b1)-1
  row.list = list()
  col.list = list()
  #cat("r= ",r)
  #print(b1)
  for(i in 1:r){
    row.list[[i]] <- rownames(x)[ b1[i]:(b1[i+1]-1) ]
    col.list[[i]] <- colnames(x)[ b2[i]:(b2[i+1]-1) ]
    #row.list[[i]] <-paste("'R",i,"' = list('",	paste(c(rownames(x)[ b1[i]:(b1[i+1]-1) ]),collapse="','"),"')",sep="")
    #col.list[[i]] <-paste("'C",i,"' = list('",	paste(c(colnames(x)[ b2[i]:(b2[i+1]-1) ]),collapse="','"),"')",sep="")
    
  }
  
  #list1 <- paste("list(",paste(row.list,collapse = ","),")",sep="")
  #list2 <- paste("list(",paste(col.list,collapse = ","),")",sep="")
  
  if(plot){
    class(x) <- "matrix"
    if(!add){
      bs <- fluctile(trafo(x), gap.prop=gap.prop, shape = shape, just = just, dir = dir, tile.col = tile.col, tile.border = tile.border, bg.col = bg.col, label = label, lab.opt = lab.opt, border = border)
    }else{
      bs <- fluctile(trafo(x), gap.prop=gap.prop, bg.col=rgb(0,0,0,alpha=0),tile.col = rgb(0,0,0,alpha=0),tile.border = tile.border, add = TRUE, shape = shape, just = just, dir = dir, label = label, lab.opt = lab.opt, border = border)	
    }
    addrect(bs, breaks, col, gap.prop, rev.y = !rev.y, lwd = lwd, lty = lty, fill = fill)
  }
  
  ret <- list(row.list,col.list)
  attr(ret,"orders") <- list( lapply(row.list, function(w) match(w,rownames(x))), lapply(col.list, function(w) match(w,colnames(x)))  )
  attr(ret,"tau.values") <- tau.values
  attr(ret,"level") <- cut.ids
  attr(ret,"cut.rank") <- cut.rank
  attr(ret,"tau0") <- tau0
  return(invisible(ret))
}

```
```{r}
data(Zoo, package="seriation")
fluctile(table(select(Zoo, c(hair, eggs:backbone))),label=FALSE)
```




### 2. Missing values and Outliers
### Missing
***
  Missing data (or missing values) is defined as the data value that is not stored for a variable in the observation of interest. The problem of missing data is relatively common in almost all research and can have a significant effect on the conclusions that can be drawn from the data. Accordingly, some studies have focused on handling the missing data, problems caused by missing data, and the methods to avoid or minimize such in medical research.

   However, until recently, most researchers have drawn conclusions based on the assumption of a complete data set. The general topic of missing data has attracted little attention in the field of anesthesiology.

   Missing data present various problems. First, the absence of data reduces statistical power, which refers to the probability that the test will reject the null hypothesis when it is false. Second, the lost data can cause bias in the estimation of parameters. Third, it can reduce the representativeness of the samples. Fourth, it may complicate the analysis of the study. Each of these distortions may threaten the validity of the trials and can lead to invalid conclusions.
   
   In aceasta parte a proiectului am construit un set de date in care este reprezentat PIB-ul pe fiecare Tara, investitia in sanatate si educatie respectiv HDI, iar tarile sunt impartite pe continent.
   
   Urmatorul cod ne permite incarcarea datelor 
   
```{r}
   data<-read.csv("data.csv",header=TRUE)
date<-data.frame(Indicator=data$Series.Code,
                 Tara=data$Country.Name,
                 Valoare=data$X2015..YR2015.
                 )
                 
Continent<-data$Continent
HDI<- data$HDI
date<-reshape(date,idvar="Tara",timevar = "Indicator",direction="wide")
date<-data.frame(Tara=date$Tara,
                 PIBperCapita=date$Valoare.NY.GDP.PCAP.PP.CD,
                 CheltEducatie=date$Valoare.SE.XPD.TOTL.GD.ZS,
                 CO2perCapita=date$Valoare.EN.ATM.CO2E.PC,
                 CheltSanatate=date$Valoare.SH.XPD.GHED.GD.ZS
                 )
date<-data.frame(date,Continent)
date<-data.frame(date,HDI)               
   
```
   
   Am prelucrat datele introduse deoarece contine valori nule si valori aberante, inlocuindule cu  valoarea lipsa.
```{r}
   for( i in 1:nrow(date)){
  for(j in 1:ncol(date)){
    if(date[i,j]==""||date[i,j]==".."){
      date[i,j]<-NA
    }
  }
}
```
   In cele ce urmeaza vom verifica numarul de valori lipsa si vim afisa un grafic pentru a ne da seama cat de mult influenteaza pentru statistica finala.
   
```{r}
vis_miss(date)
```

Din grafic se observa o lipsa a detelor de 12% dintre care 48 % sunt cheltuielile folosite pentru educatie, ceea ce ce in final la o statistia a raportului de cheltuieli educatie si chelutieli sanatate ar duce la o discrepanta foarte mare, asadar le vom elimina folosind functia _na.omit()_. 
 
```{r}
date<-na.omit(date)
vis_miss(date)
```

### Outliers
***

An outlier is an observation that lies an abnormal distance from other values in a random sample from a population. In a sense, this definition leaves it up to the analyst (or a consensus process) to decide what will be considered abnormal.

Before abnormal observations can be singled out, it is necessary to characterize normal observations.

Two activities are essential for characterizing a set of data:

1. Examination of the overall shape of the graphed data for important features, including symmetry and departures from assumptions. The chapter on Exploratory Data Analysis (EDA) discusses assumptions and summarization of data in detail.

2. Examination of the data for unusual observations that are far removed from the mass of data. These points are often referred to as outliers. Two graphical techniques for identifying outliers, scatter plots and box plots, along with an analytic procedure for detecting outliers when the distribution is normal (Grubbs' Test), are also discussed in detail in the EDA chapter.


Pentru a putea folosi datele trebuie sa le transformate in valori numerice pentru a putea fi scalate
```{r}
date$CO2perCapita<-as.numeric(date$CO2perCapita)
date$HDI<-as.numeric(date$HDI)
date$CheltEducatie<-as.numeric(date$CheltEducatie)
date$CheltSanatate<-as.numeric(date$CheltSanatate)
date$PIBperCapita<-as.numeric(date$PIBperCapita)
```

Pentru prima parte dorim sa verificam daca exista Outliers pentru PIB pentru toate tarile.

***
Pentru a determina eventualele valori Outliers vom folosi Box plot construction.

The box plot is a useful graphical display for describing the behavior of the data in the middle as well as at the ends of the distributions. The box plot uses the median and the lower and upper quartiles (defined as the 25th and 75th percentiles). If the lower quartile is Q1 and the upper quartile is Q3, then the difference (Q3 - Q1) is called the interquartile range or IQ.

A box plot is constructed by drawing a box between the upper and lower quartiles with a solid line drawn across the box to locate the median. The following quantities (called fences) are needed for identifying extreme values in the tails of the distribution:

  a. lower inner fence: Q1 - 1.5*IQ
  b. upper inner fence: Q3 + 1.5*IQ
  c. lower outer fence: Q1 - 3*IQ
  d. upper outer fence: Q3 + 3*IQ

Outlier detection criteria:

1. A point beyond an inner fence on either side is considered a mild outlier. 
2. A point beyond an outer fence is considered an extreme outlier.

***

Ne dorim sa facem o statisca asupra PIB-ului, si dorim sa aflam eventualele valori extreme.
```{r}
ggplot(date, aes("PIB all Continent", y=PIBperCapita)) +
  xlab("") + geom_boxplot() +
  scale_x_discrete(breaks=NULL)

```

Se observa 2 valori extreme aporximativ 7000 respectiv 10000 momentan nu putem spune daca influenteaza sau nu. Vom incercasa sa ne dam seama de influenta acestor valori comparand cu PIB-urile pe fiecare continent.

```{r}
all <- ggplot(date, aes("PIB all Continent", y=PIBperCapita)) +
  xlab("") + geom_boxplot() +
  scale_x_discrete(breaks=NULL)

continent1<-ggplot(date, aes(x=Continent, y=PIBperCapita)) +
  geom_boxplot() + xlab("") 
grid.arrange(all,continent1, nrow=1,widths=c(1,2))

```

Din graficul anterios putem observa ca punctele extreme provin de pe continentul Europa, iar  Outliers provenite din Africa nu influenteaza statistica finala deoarce sunt cuprinse de celelalte contine, de unde putem deduce usor ca Africa este un continent sarac.

Dorim acum sa vedem cand se investe din PIB in educatie respectiv sanatate.

```{r}
educatie <- ggplot(date, aes(y=CheltEducatie, x=Continent)) +
  xlab("") + geom_boxplot() +
  scale_y_discrete(breaks=NULL)

sanatate <- ggplot(date, aes(y=CheltSanatate, x=Continent)) +
  xlab("") + geom_boxplot() +
  scale_y_discrete(breaks=NULL)
grid.arrange(educatie,sanatate)



```

Se observa ca America de Sud investeste in mod egal si in eduatie si sanatate, iar pe continetul Asia exista un Outlier pentru cheluielile pe Sanatete de unde putem deduce ca exista un numar finit si da tari care investesc mai mult in sanatete fata de celelalte.

Nu vom elimina nici acest Outlier, deoarce este si e el cuprins de media celorlalte continente.


In final pentru a vedea investitia in sanatate respectiv educate din PIB pentru fiecare Tara  vom afisa 2 grafice. Primul ne masoara in functie de PIB pentru fiecare tara, iar cel de al doilea ne afiseaza raportul tarilor pentru fiecare continent. Se observa ca majoritatea tarilol investec in mod egal atat in sanatate cat si in educatie.


```{r}
ggplot(date)+aes(x=CheltSanatate,y=CheltEducatie ,colour=PIBperCapita )+geom_point()

```
```{r}
ggplot(data=date)+ aes(x=CheltSanatate,y=CheltEducatie,colour=Continent) + geom_point() +
  geom_density2d(bins=5, col="red")

```

### Exercitii

1). 
<center>
![](ExercitiiImagini/OutEx1.jpg)
</center>

```{r}
library(survival)
date<-lung
date
View(date)

vis_miss(date)

```

Exista valori lipsa pentru mai multe variabile, dar cele mai multe se gasesc la variabila "meal.cal", urmata de variabila
"wt.loss" si sunt putine observatii care au aceste valori lipsa pentru ambele variabile in acelasi timp
Avem cate o valoare lipsa si pentru variabilele "inst, ph.ecog si ph.kamo", dar aceasta nu lipseste pentru aceeasi observatie
### Va multumim






